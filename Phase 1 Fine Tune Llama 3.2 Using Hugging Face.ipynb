{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9983211,"sourceType":"datasetVersion","datasetId":6143322},{"sourceId":120005,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:07:48.559927Z","iopub.execute_input":"2024-11-30T06:07:48.560227Z","iopub.status.idle":"2024-11-30T06:07:48.898062Z","shell.execute_reply.started":"2024-11-30T06:07:48.560187Z","shell.execute_reply":"2024-11-30T06:07:48.897270Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/customer-support-training-dataset-27k/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/model.safetensors.index.json\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/config.json\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00001-of-00002.safetensors\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00002-of-00002.safetensors\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/README.md\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/USE_POLICY.md\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer.json\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer_config.json\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/LICENSE.txt\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/special_tokens_map.json\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/.gitattributes\n/kaggle/input/llama-3.2/transformers/3b-instruct/1/generation_config.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:07:48.899124Z","iopub.execute_input":"2024-11-30T06:07:48.899506Z","iopub.status.idle":"2024-11-30T06:08:47.685870Z","shell.execute_reply.started":"2024-11-30T06:07:48.899476Z","shell.execute_reply":"2024-11-30T06:08:47.684898Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Access LLama from Kaggle. We can also access it from hugging face but we will use Kaggle this time.\n* Go to the https://www.kaggle.com/models/metaresearch/llama-3.2 website\n* There will be a link fill out the form at https://www.llama.com/llama-downloads/ website\n* Select both lightweight and vision models. Your Name, DOB should be same as in your Gmail ID and your Kaggle Account. Fill Organization as Kaggle if logining from Kaggle if you are trying to access model from Hugging Face fill organization as Hugging Face.\n* After getting access from make a new notebook click on add input and add the meta llama model.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer\nimport torch\n\n\nbase_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    return_dict=True,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:08:47.691175Z","iopub.execute_input":"2024-11-30T06:08:47.691444Z","iopub.status.idle":"2024-11-30T06:09:41.188779Z","shell.execute_reply.started":"2024-11-30T06:08:47.691415Z","shell.execute_reply":"2024-11-30T06:09:41.188112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2aca3b36c024517abea880836d9c49c"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"Set pad_token_id to avoid receiving warning messages.\n","metadata":{}},{"cell_type":"code","source":"if tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = model.config.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:09:41.189891Z","iopub.execute_input":"2024-11-30T06:09:41.190542Z","iopub.status.idle":"2024-11-30T06:09:41.195073Z","shell.execute_reply.started":"2024-11-30T06:09:41.190501Z","shell.execute_reply":"2024-11-30T06:09:41.194222Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:01.016348Z","iopub.execute_input":"2024-11-30T06:10:01.016684Z","iopub.status.idle":"2024-11-30T06:10:01.021979Z","shell.execute_reply.started":"2024-11-30T06:10:01.016655Z","shell.execute_reply":"2024-11-30T06:10:01.021102Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Where is delhi\"}]\n\nprompt = tokenizer.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\n\noutputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:04.230016Z","iopub.execute_input":"2024-11-30T06:10:04.230440Z","iopub.status.idle":"2024-11-30T06:10:09.066942Z","shell.execute_reply.started":"2024-11-30T06:10:04.230402Z","shell.execute_reply":"2024-11-30T06:10:09.066082Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nWhere is delhi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nDelhi is the capital city of India, located in the northern part of the country. It is situated in the Indo-Gangetic Plain, which is a fertile region along the Yamuna River.\n\nGeographically, Delhi is located in the National Capital Territory of Delhi (NCT) and is surrounded by the following states:\n\n* Haryana to the north and west\n* Uttar Pradesh to the east\n* Rajasthan to the southwest\n\nDelhi is also a major urban agglomeration, with a population of over 29 million people, making it one of the largest cities in the world.\n\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Fine-tuning Llama 3.2 3B Instruct Using LoRA On top of Qlora 4 bit Quantizattion","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:09.682190Z","iopub.execute_input":"2024-11-30T06:10:09.682587Z","iopub.status.idle":"2024-11-30T06:10:11.279159Z","shell.execute_reply.started":"2024-11-30T06:10:09.682557Z","shell.execute_reply":"2024-11-30T06:10:11.278255Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:11.280804Z","iopub.execute_input":"2024-11-30T06:10:11.281361Z","iopub.status.idle":"2024-11-30T06:10:11.574505Z","shell.execute_reply.started":"2024-11-30T06:10:11.281332Z","shell.execute_reply":"2024-11-30T06:10:11.573634Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model = \"llama-3.2-3b-it-CustomerSupport-ChatBot\"\ndataset_name = \"/kaggle/input/customer-support-training-dataset-27k/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:18.062135Z","iopub.execute_input":"2024-11-30T06:10:18.062503Z","iopub.status.idle":"2024-11-30T06:10:18.068031Z","shell.execute_reply.started":"2024-11-30T06:10:18.062473Z","shell.execute_reply":"2024-11-30T06:10:18.066926Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Loading the model and tokenizer\n* Setting the data type and attention implementation based on GPU.","metadata":{}},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:19.830998Z","iopub.execute_input":"2024-11-30T06:10:19.831445Z","iopub.status.idle":"2024-11-30T06:10:19.837166Z","shell.execute_reply.started":"2024-11-30T06:10:19.831412Z","shell.execute_reply":"2024-11-30T06:10:19.836325Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Load the model and tokenizer by providing the local model directory. Even though our model is small, loading the full model and fine-tuning it will take some time. Instead, we will load the model in 4-bit quantization which is referred as QLora.s.","metadata":{}},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:22.173608Z","iopub.execute_input":"2024-11-30T06:10:22.174457Z","iopub.status.idle":"2024-11-30T06:10:30.391783Z","shell.execute_reply.started":"2024-11-30T06:10:22.174421Z","shell.execute_reply":"2024-11-30T06:10:30.390750Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6eef32335f49dc9edb9be81aabbf5f"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:30.418321Z","iopub.execute_input":"2024-11-30T06:10:30.418639Z","iopub.status.idle":"2024-11-30T06:10:30.427952Z","shell.execute_reply.started":"2024-11-30T06:10:30.418598Z","shell.execute_reply":"2024-11-30T06:10:30.427011Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Loading and processing the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(dataset_name)\ndf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:30.429495Z","iopub.execute_input":"2024-11-30T06:10:30.429744Z","iopub.status.idle":"2024-11-30T06:10:30.891509Z","shell.execute_reply.started":"2024-11-30T06:10:30.429720Z","shell.execute_reply":"2024-11-30T06:10:30.890524Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"flags          0\ninstruction    0\ncategory       0\nintent         0\nresponse       0\ndtype: int64"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:30.892619Z","iopub.execute_input":"2024-11-30T06:10:30.892967Z","iopub.status.idle":"2024-11-30T06:10:30.906454Z","shell.execute_reply.started":"2024-11-30T06:10:30.892939Z","shell.execute_reply":"2024-11-30T06:10:30.905427Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  flags                                        instruction category  \\\n0     B   question about cancelling order {{Order Number}}    ORDER   \n1   BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n2  BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n\n         intent                                           response  \n0  cancel_order  I've understood you have a question regarding ...  \n1  cancel_order  I've been informed that you have a question ab...  \n2  cancel_order  I can sense that you're seeking assistance wit...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flags</th>\n      <th>instruction</th>\n      <th>category</th>\n      <th>intent</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B</td>\n      <td>question about cancelling order {{Order Number}}</td>\n      <td>ORDER</td>\n      <td>cancel_order</td>\n      <td>I've understood you have a question regarding ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BQZ</td>\n      <td>i have a question about cancelling oorder {{Or...</td>\n      <td>ORDER</td>\n      <td>cancel_order</td>\n      <td>I've been informed that you have a question ab...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BLQZ</td>\n      <td>i need help cancelling puchase {{Order Number}}</td>\n      <td>ORDER</td>\n      <td>cancel_order</td>\n      <td>I can sense that you're seeking assistance wit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Already the dataset is quite cleaned. But we will take only those columns which are requrired for best Fine Tuning.","metadata":{}},{"cell_type":"code","source":"df = df.drop(['flags', 'category','intent'], axis=1)\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:33.554528Z","iopub.execute_input":"2024-11-30T06:10:33.554877Z","iopub.status.idle":"2024-11-30T06:10:33.568632Z","shell.execute_reply.started":"2024-11-30T06:10:33.554846Z","shell.execute_reply":"2024-11-30T06:10:33.567764Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                         instruction  \\\n0   question about cancelling order {{Order Number}}   \n1  i have a question about cancelling oorder {{Or...   \n2    i need help cancelling puchase {{Order Number}}   \n\n                                            response  \n0  I've understood you have a question regarding ...  \n1  I've been informed that you have a question ab...  \n2  I can sense that you're seeking assistance wit...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>question about cancelling order {{Order Number}}</td>\n      <td>I've understood you have a question regarding ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i have a question about cancelling oorder {{Or...</td>\n      <td>I've been informed that you have a question ab...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i need help cancelling puchase {{Order Number}}</td>\n      <td>I can sense that you're seeking assistance wit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"df.to_csv('updated_dataset.csv', index=False)\ndataset_nam = \"/kaggle/working/updated_dataset.csv\"\nlen(pd.read_csv(dataset_name))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:33.888314Z","iopub.execute_input":"2024-11-30T06:10:33.888655Z","iopub.status.idle":"2024-11-30T06:10:34.591870Z","shell.execute_reply.started":"2024-11-30T06:10:33.888625Z","shell.execute_reply":"2024-11-30T06:10:34.591014Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"26872"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('csv', data_files=dataset_nam, split='all')\n# Shuffle the dataset and select the first 1000 samples\ndataset = dataset.shuffle(seed=65).select(range(1000))\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:35.365651Z","iopub.execute_input":"2024-11-30T06:10:35.365980Z","iopub.status.idle":"2024-11-30T06:10:35.950811Z","shell.execute_reply.started":"2024-11-30T06:10:35.365953Z","shell.execute_reply":"2024-11-30T06:10:35.950107Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a29c0ecbac43658f5e65e65050793b"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'response'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"dataset['instruction'][0],dataset['response'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:36.011449Z","iopub.execute_input":"2024-11-30T06:10:36.011700Z","iopub.status.idle":"2024-11-30T06:10:36.034833Z","shell.execute_reply.started":"2024-11-30T06:10:36.011674Z","shell.execute_reply":"2024-11-30T06:10:36.034171Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('where do i enter a different shipping address',\n 'Ah, I understand that you\\'re looking to enter a different shipping address. Allow me to guide you through the process:\\n\\n1. Log in to your account on our website.\\n2. Navigate to the \"My Account\" or \"Profile\" section, which can usually be found in the top right corner of the page.\\n3. Look for the \"Shipping Addresses\" or similar option. It may also be labeled as \"Manage Addresses\" or \"Delivery Information.\"\\n4. Click on that option to access your saved addresses.\\n5. To enter a different shipping address, you\\'ll most likely have the choice to either \"Edit\" an existing address or \"Add a New Address.\"\\n6. If you choose to edit, find the address you want to update and click on the \"Edit\" or \"Modify\" button. Make your changes and then save.\\n7. If you want to add a completely new address, click on the \"Add a New Address\" or a similar option. Fill in the necessary details and save.\\n\\nRemember to double-check all the information you enter to ensure the accuracy of your shipping address. If you encounter any issues or have further questions, please don\\'t hesitate to ask. We\\'re here to support you every step of the way!')"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"# Model Response Before Fine Tuning","metadata":{}},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"where do i enter a different shipping address\"}]\n\nprompt = tokenizer.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\n\noutputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:37.293349Z","iopub.execute_input":"2024-11-30T06:10:37.293672Z","iopub.status.idle":"2024-11-30T06:10:41.103654Z","shell.execute_reply.started":"2024-11-30T06:10:37.293645Z","shell.execute_reply":"2024-11-30T06:10:41.102709Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nwhere do i enter a different shipping address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo enter a different shipping address, the steps may vary slightly depending on the platform or website you're using. Here are some general steps for popular online shopping platforms:\n\n**Amazon:**\n\n1. Sign in to your Amazon account.\n2. Go to the product details page.\n3. Click on \"Shipping\" or \"Delivery\" (usually located at the top of the page).\n4. Select \"Enter a different shipping address\" or \"Add a new shipping address\".\n5. Enter the new shipping address and click \"Save\".\n\n**eBay:**\n\n1. Sign in to your eBay account.\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Preparing Dataset For LLama 3.2 Fine Tuning","metadata":{}},{"cell_type":"code","source":"instruction = \"\"\"You are a top-rated customer service agent named John. \n    Be polite to customers and answer all their questions.\n    \"\"\"\ndef format_chat_template(row):\n    \n    row_json = [{\"role\": \"system\", \"content\": instruction },\n               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n    \n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\ndataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:41.105498Z","iopub.execute_input":"2024-11-30T06:10:41.106187Z","iopub.status.idle":"2024-11-30T06:10:41.848615Z","shell.execute_reply.started":"2024-11-30T06:10:41.106143Z","shell.execute_reply":"2024-11-30T06:10:41.847827Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95db38fededf4d10ba45f1d0013737bd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'response', 'text'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"print(dataset['text'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:41.849913Z","iopub.execute_input":"2024-11-30T06:10:41.850189Z","iopub.status.idle":"2024-11-30T06:10:41.858826Z","shell.execute_reply.started":"2024-11-30T06:10:41.850160Z","shell.execute_reply":"2024-11-30T06:10:41.858103Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a top-rated customer service agent named John. \n    Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nwhere do i enter a different shipping address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nAh, I understand that you're looking to enter a different shipping address. Allow me to guide you through the process:\n\n1. Log in to your account on our website.\n2. Navigate to the \"My Account\" or \"Profile\" section, which can usually be found in the top right corner of the page.\n3. Look for the \"Shipping Addresses\" or similar option. It may also be labeled as \"Manage Addresses\" or \"Delivery Information.\"\n4. Click on that option to access your saved addresses.\n5. To enter a different shipping address, you'll most likely have the choice to either \"Edit\" an existing address or \"Add a New Address.\"\n6. If you choose to edit, find the address you want to update and click on the \"Edit\" or \"Modify\" button. Make your changes and then save.\n7. If you want to add a completely new address, click on the \"Add a New Address\" or a similar option. Fill in the necessary details and save.\n\nRemember to double-check all the information you enter to ensure the accuracy of your shipping address. If you encounter any issues or have further questions, please don't hesitate to ask. We're here to support you every step of the way!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Setting up the model\n1. Purpose of the Function: The function helps identify which layers are eligible for lora modifications (in this case, bnb.nn.Linear4bit layers), enabling efficient fine-tuning. By pinpointing these layers, practitioners can focus adaptation efforts where they are most impactful, without changing the entire model.","metadata":{}},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:41.860779Z","iopub.execute_input":"2024-11-30T06:10:41.861023Z","iopub.status.idle":"2024-11-30T06:10:41.875751Z","shell.execute_reply.started":"2024-11-30T06:10:41.860999Z","shell.execute_reply":"2024-11-30T06:10:41.874934Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"Lora Technique for efficent Fine Tuning","metadata":{}},{"cell_type":"code","source":"# LoRA config\ntokenizer.chat_template = None\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:41.876835Z","iopub.execute_input":"2024-11-30T06:10:41.877084Z","iopub.status.idle":"2024-11-30T06:10:48.825072Z","shell.execute_reply.started":"2024-11-30T06:10:41.877060Z","shell.execute_reply":"2024-11-30T06:10:48.824131Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Hyperparameters\n# Below is a list of hyperparameters that can be used to optimize the training process:\r\n* \r\noutput_dir: The output directory is where the model predictions and checkpoints will be store\n* .\r\nnum_train_epochs: One training epo\n* h.\r\nfp16/bf16: Disable fp16/bf16 train\n* ng.\r\nper_device_train_batch_size: Batch size per GPU for trai\n* \nper_device_eval_batch_size: Batch size per GPU for evaluation\n* \r\ngradient_accumulation_steps: This refers to the number of steps required to accumulate the gradients during the update proces\n* .\r\ngradient_checkpointing: Enabling gradient checkpointi\n* ng.\r\nmax_grad_norm: Gradient clipp\n* ing.\r\nlearning_rate: Initial learning \n* rate.\r\nweight_decay: Weight decay is applied to all layers except bias/LayerNorm we\n* ights.\r\nOptim: Model optimizer (AdamW opti\n* mizer).\r\nlr_scheduler_type: Learning rate s\n* chedule.\r\nmax_steps: Number of traini\n* ng steps.\r\nwarmup_ratio: Ratio of steps for a line\n* ar warmup.\r\ngroup_by_length: This can significantly improve performance and accelerate the traini\n* ng process.\r\nsave_steps: Save checkpoint every 25 u\n* pdate steps.\r\nlogging_st\neps: Log every 25 update steps.","metadata":{}},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:52.109970Z","iopub.execute_input":"2024-11-30T06:10:52.110936Z","iopub.status.idle":"2024-11-30T06:10:52.127007Z","shell.execute_reply.started":"2024-11-30T06:10:52.110897Z","shell.execute_reply":"2024-11-30T06:10:52.126148Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'response', 'text'],\n        num_rows: 900\n    })\n    test: Dataset({\n        features: ['instruction', 'response', 'text'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:54.669143Z","iopub.execute_input":"2024-11-30T06:10:54.669514Z","iopub.status.idle":"2024-11-30T06:10:54.698808Z","shell.execute_reply.started":"2024-11-30T06:10:54.669484Z","shell.execute_reply":"2024-11-30T06:10:54.697927Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"Setting Supervised Fine tuning parameters","metadata":{}},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:10:58.126507Z","iopub.execute_input":"2024-11-30T06:10:58.127491Z","iopub.status.idle":"2024-11-30T06:22:48.505293Z","shell.execute_reply.started":"2024-11-30T06:10:58.127452Z","shell.execute_reply":"2024-11-30T06:22:48.504428Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c55eb4699194044a681863f1f3bc8f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54ea985e25d4d98933388eeaa282074"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [450/450 11:46, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>0.812300</td>\n      <td>0.814006</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.841100</td>\n      <td>0.731385</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.999200</td>\n      <td>0.698661</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.716700</td>\n      <td>0.669213</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.489700</td>\n      <td>0.653303</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=450, training_loss=0.7693972663084666, metrics={'train_runtime': 708.9126, 'train_samples_per_second': 1.27, 'train_steps_per_second': 0.635, 'total_flos': 2768436576362496.0, 'train_loss': 0.7693972663084666, 'epoch': 1.0})"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"The training loss gradually reduced. Which means we are doing fine with small dataset, so we can increase the data depending on the gpu available.\n","metadata":{}},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing the model Again \n* We will see that accuracy is changed know, w.r.t previous results.","metadata":{}},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instruction},\n    {\"role\": \"user\", \"content\": \"where do i enter a different shipping address?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens=200, num_return_sequences=1)\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T06:22:57.305622Z","iopub.execute_input":"2024-11-30T06:22:57.306000Z","iopub.status.idle":"2024-11-30T06:23:21.261382Z","shell.execute_reply.started":"2024-11-30T06:22:57.305965Z","shell.execute_reply":"2024-11-30T06:23:21.260507Z"}},"outputs":[{"name":"stdout","text":"\nI've got that you're looking to enter a different shipping address. To do this, you can visit the \"My Account\" section on our website and navigate to the \"Shipping Addresses\" or \"Address Book\" section. From there, you can add a new shipping address or edit an existing one. If you need any further assistance or have any other questions, please don't hesitate to ask.system\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"#  Saving the tokenizer and model","metadata":{}},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make sure to save the notebook with the outputs\n* Follow Phase 2 Merging and Exporting Fine-tuned Llama 3.2 ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}