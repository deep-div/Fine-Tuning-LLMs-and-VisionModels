# ðŸ§  Fine-Tuning LLMs (Gemma, LLaMA, Mistral, and More)

Welcome to this curated repository showcasing the fine-tuning of various open-source large language models (LLMs) such as **Gemma**, **LLaMA**, **Mistral**, and others using **Hugging Face Transformers**, **PEFT (LoRA/QLoRA)**, and other modern libraries.

This repo is designed for researchers, ML engineers, and enthusiasts looking to explore or build on top of custom fine-tuned LLMs.
 

## ðŸ”§ Features

* âœ… Fine-tuning with Hugging Face Trainer and PEFT (LoRA / QLoRA)
* âœ… Dataset loading and preprocessing
* âœ… Tokenization and model configuration
* âœ… Evaluation with custom metrics
* âœ… Easy-to-edit configs for reproducibility
* âœ… Support for mixed precision (fp16, bf16)


## ðŸ§  Contributing

Got improvements, additional models, or tips? Contributions are welcome! Just open an issue or submit a pull request.

